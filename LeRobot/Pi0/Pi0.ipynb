{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfcfbea8",
   "metadata": {},
   "source": [
    "# Pi0 Policy with Lerobot\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- Conda env : [lerobot](../README.md#setup-a-conda-environment)\n",
    "\n",
    "----\n",
    "\n",
    "- Ref: \n",
    "    - https://huggingface.co/lerobot/pi0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ff151",
   "metadata": {},
   "source": [
    "## Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312335f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device : mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Available device : {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7356e332",
   "metadata": {},
   "source": [
    "##  Train the pi0 policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f2319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2025-10-07 09:22:38 ts/train.py:111 {'batch_size': 16,\n",
      " 'dataset': {'episodes': None,\n",
      "             'image_transforms': {'enable': False,\n",
      "                                  'max_num_transforms': 3,\n",
      "                                  'random_order': False,\n",
      "                                  'tfs': {'brightness': {'kwargs': {'brightness': [0.8,\n",
      "                                                                                   1.2]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'contrast': {'kwargs': {'contrast': [0.8,\n",
      "                                                                               1.2]},\n",
      "                                                       'type': 'ColorJitter',\n",
      "                                                       'weight': 1.0},\n",
      "                                          'hue': {'kwargs': {'hue': [-0.05,\n",
      "                                                                     0.05]},\n",
      "                                                  'type': 'ColorJitter',\n",
      "                                                  'weight': 1.0},\n",
      "                                          'saturation': {'kwargs': {'saturation': [0.5,\n",
      "                                                                                   1.5]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'sharpness': {'kwargs': {'sharpness': [0.5,\n",
      "                                                                                 1.5]},\n",
      "                                                        'type': 'SharpnessJitter',\n",
      "                                                        'weight': 1.0}}},\n",
      "             'repo_id': 'danaaubakirova/koch_test',\n",
      "             'revision': None,\n",
      "             'root': None,\n",
      "             'use_imagenet_stats': True,\n",
      "             'video_backend': 'torchcodec'},\n",
      " 'env': None,\n",
      " 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},\n",
      " 'eval_freq': 25,\n",
      " 'job_name': 'pi0',\n",
      " 'log_freq': 200,\n",
      " 'num_workers': 4,\n",
      " 'optimizer': {'betas': [0.9, 0.95],\n",
      "               'eps': 1e-08,\n",
      "               'grad_clip_norm': 10.0,\n",
      "               'lr': 2.5e-05,\n",
      "               'type': 'adamw',\n",
      "               'weight_decay': 1e-10},\n",
      " 'output_dir': 'temp/outputs',\n",
      " 'policy': {'adapt_to_pi_aloha': False,\n",
      "            'attention_implementation': 'eager',\n",
      "            'chunk_size': 50,\n",
      "            'device': 'mps',\n",
      "            'empty_cameras': 0,\n",
      "            'freeze_vision_encoder': True,\n",
      "            'input_features': {'observation.images.camera0': {'shape': [3,\n",
      "                                                                        480,\n",
      "                                                                        640],\n",
      "                                                              'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.images.camera1': {'shape': [3,\n",
      "                                                                        480,\n",
      "                                                                        640],\n",
      "                                                              'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.images.camera2': {'shape': [3,\n",
      "                                                                        480,\n",
      "                                                                        640],\n",
      "                                                              'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.state': {'shape': [6],\n",
      "                                                     'type': <FeatureType.STATE: 'STATE'>}},\n",
      "            'license': None,\n",
      "            'max_action_dim': 32,\n",
      "            'max_state_dim': 32,\n",
      "            'n_action_steps': 50,\n",
      "            'n_obs_steps': 1,\n",
      "            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>},\n",
      "            'num_steps': 10,\n",
      "            'optimizer_betas': [0.9, 0.95],\n",
      "            'optimizer_eps': 1e-08,\n",
      "            'optimizer_lr': 2.5e-05,\n",
      "            'optimizer_weight_decay': 1e-10,\n",
      "            'output_features': {'action': {'shape': [6],\n",
      "                                           'type': <FeatureType.ACTION: 'ACTION'>}},\n",
      "            'private': None,\n",
      "            'proj_width': 1024,\n",
      "            'push_to_hub': False,\n",
      "            'repo_id': None,\n",
      "            'resize_imgs_with_padding': [224, 224],\n",
      "            'scheduler_decay_lr': 2.5e-06,\n",
      "            'scheduler_decay_steps': 30000,\n",
      "            'scheduler_warmup_steps': 1000,\n",
      "            'tags': None,\n",
      "            'tokenizer_max_length': 48,\n",
      "            'train_expert_only': False,\n",
      "            'train_state_proj': True,\n",
      "            'type': 'pi0',\n",
      "            'use_amp': False,\n",
      "            'use_cache': True,\n",
      "            'use_delta_joint_actions_aloha': False},\n",
      " 'resume': False,\n",
      " 'save_checkpoint': True,\n",
      " 'save_freq': 25000,\n",
      " 'scheduler': {'decay_lr': 2.5e-06,\n",
      "               'num_decay_steps': 30000,\n",
      "               'num_warmup_steps': 1000,\n",
      "               'peak_lr': 2.5e-05,\n",
      "               'type': 'cosine_decay_with_warmup'},\n",
      " 'seed': 100000,\n",
      " 'steps': 200000,\n",
      " 'use_policy_training_preset': True,\n",
      " 'wandb': {'disable_artifact': False,\n",
      "           'enable': False,\n",
      "           'entity': None,\n",
      "           'mode': None,\n",
      "           'notes': None,\n",
      "           'project': 'lerobot',\n",
      "           'run_id': None}}\n",
      "INFO 2025-10-07 09:22:38 ts/train.py:117 \u001b[1m\u001b[33mLogs will be saved locally.\u001b[0m\n",
      "INFO 2025-10-07 09:22:38 ts/train.py:127 Creating dataset\n",
      "WARNING 2025-10-07 09:22:38 ts/utils.py:302 \n",
      "The dataset you requested (danaaubakirova/koch_test) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python -m lerobot.datasets.v21.convert_dataset_v20_to_v21 --repo-id=danaaubakirova/koch_test\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "WARNING 2025-10-07 09:22:38 ts/utils.py:302 \n",
      "The dataset you requested (danaaubakirova/koch_test) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python -m lerobot.datasets.v21.convert_dataset_v20_to_v21 --repo-id=danaaubakirova/koch_test\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Resolving data files: 100%|█████████████████| 51/51 [00:00<00:00, 435660.90it/s]\n",
      "INFO 2025-10-07 09:22:39 ts/train.py:138 Creating policy\n",
      "⚠️  DISCLAIMER: The PI0 model is ported from JAX by the Hugging Face team. \n",
      "   It is not expected to perform as well as the original implementation. \n",
      "   Original implementation: https://github.com/Physical-Intelligence/openpi\n",
      "WARNING 2025-10-07 09:23:46 ies/utils.py:85 Missing key(s) when loading model: ['normalize_inputs.buffer_observation_state.mean', 'normalize_inputs.buffer_observation_state.std', 'normalize_targets.buffer_action.mean', 'normalize_targets.buffer_action.std', 'unnormalize_outputs.buffer_action.mean', 'unnormalize_outputs.buffer_action.std', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.post_layernorm.weight', 'model.paligemma_with_expert.paligemma.vision_tower.vision_model.post_layernorm.bias', 'model.paligemma_with_expert.paligemma.multi_modal_projector.linear.weight', 'model.paligemma_with_expert.paligemma.multi_modal_projector.linear.bias', 'model.paligemma_with_expert.paligemma.language_model.model.embed_tokens.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.0.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.1.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.2.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.3.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.4.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.5.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.6.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.7.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.8.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.9.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.10.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.11.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.12.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.13.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.14.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.15.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.16.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.layers.17.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.language_model.model.norm.weight', 'model.paligemma_with_expert.paligemma.language_model.lm_head.weight']\n",
      "WARNING 2025-10-07 09:23:46 ies/utils.py:87 Unexpected key(s) when loading model: ['model.paligemma_with_expert.paligemma.lm_head.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.0.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.1.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.10.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.11.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.12.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.13.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.14.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.15.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.16.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.17.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.2.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.3.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.4.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.5.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.6.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.7.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.8.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.input_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.mlp.down_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.mlp.gate_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.mlp.up_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.post_attention_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.self_attn.o_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.layers.9.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.language_model.norm.weight', 'model.paligemma_with_expert.paligemma.model.multi_modal_projector.linear.bias', 'model.paligemma_with_expert.paligemma.model.multi_modal_projector.linear.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.26.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.post_layernorm.bias', 'model.paligemma_with_expert.paligemma.model.vision_tower.vision_model.post_layernorm.weight', 'model.paligemma_with_expert.paligemma.model.language_model.embed_tokens.weight']\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:144 Creating optimizer and scheduler\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:156 \u001b[1m\u001b[33mOutput dir:\u001b[0m temp/outputs\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:159 cfg.steps=200000 (200K)\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:160 dataset.num_frames=16602 (17K)\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:161 dataset.num_episodes=51\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:162 num_learnable_params=3088929824 (3B)\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:163 num_total_params=3501372212 (4B)\n",
      "INFO 2025-10-07 09:23:49 ts/train.py:202 Start offline training on a fixed dataset\n",
      "objc[50248]: Class AVFFrameReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x11cae43a8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x1341d8800). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[50249]: Class AVFFrameReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x11e4583a8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x15b1e4800). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[50246]: Class AVFFrameReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x1264003a8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x137490800). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[50247]: Class AVFFrameReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x1157543a8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x126fa4800). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[50248]: Class AVFAudioReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x11cae43f8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x1341d8850). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[50249]: Class AVFAudioReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x11e4583f8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x15b1e4850). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[50246]: Class AVFAudioReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x1264003f8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x137490850). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n",
      "objc[50247]: Class AVFAudioReceiver is implemented in both /Users/hyunjae.k/anaconda3/envs/lerobot/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x1157543f8) and /Users/hyunjae.k/anaconda3/envs/lerobot/lib/libavdevice.60.3.100.dylib (0x126fa4850). This may cause spurious casting failures and mysterious crashes. One of the duplicates must be removed or renamed.\n"
     ]
    }
   ],
   "source": [
    "!python -m lerobot.scripts.train --output_dir=./temp/outputs/ \\\n",
    "    --policy.path=lerobot/pi0 \\\n",
    "    --dataset.repo_id=danaaubakirova/koch_test \\\n",
    "    --seed=100000 \\\n",
    "    --batch_size=16 \\\n",
    "    --steps=200000 \\\n",
    "    --eval_freq=25 \\\n",
    "    --save_freq=25000 \\\n",
    "    --policy.device=$device \\\n",
    "    --policy.push_to_hub=false \\\n",
    "    --wandb.enable=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2b715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
