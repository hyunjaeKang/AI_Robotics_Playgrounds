{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babb853d",
   "metadata": {},
   "source": [
    "# Train SmolVLA with FineTuning\n",
    "\n",
    "---\n",
    "\n",
    "- Conda env : [lerobot](../README.md#setup-a-conda-environment)\n",
    "\n",
    "----\n",
    "\n",
    "- Ref: \n",
    "    - ...\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee2dec",
   "metadata": {},
   "source": [
    "### Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb4fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Available device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fadbdf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 10 07:51:08 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 43%   46C    P2             65W /  250W |    5318MiB /  11264MiB |     17%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2130      G   /usr/lib/xorg/Xorg                      825MiB |\n",
      "|    0   N/A  N/A            2359      G   /usr/bin/gnome-shell                    150MiB |\n",
      "|    0   N/A  N/A            3725      G   /usr/share/code/code                    338MiB |\n",
      "|    0   N/A  N/A            4105      G   ...ersion=20250909-050100.006000        169MiB |\n",
      "|    0   N/A  N/A           56566      C   ...onda3/envs/lerobot/bin/python       3732MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if device == \"cuda\":\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c16a5d",
   "metadata": {},
   "source": [
    "## DataSet(svla-so101_pickplace) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d547ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████████████| 50/50 [00:00<00:00, 89088.87it/s]\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:09Z \u001b[0m\u001b[32mINFO \u001b[0m winit::platform_impl::linux::x11::window\u001b[0m\u001b[38;5;8m]\u001b[0m Guessed window scale factor: 1\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::egl\u001b[0m\u001b[38;5;8m]\u001b[0m No config found!\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::egl\u001b[0m\u001b[38;5;8m]\u001b[0m EGL says it can present to the window but not natively\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::adapter\u001b[0m\u001b[38;5;8m]\u001b[0m Max vertex attribute stride unknown. Assuming it is 2048\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::adapter\u001b[0m\u001b[38;5;8m]\u001b[0m Max vertex attribute stride unknown. Assuming it is 2048\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:10Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:11Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:24:11Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "100%|███████████████████████████████████████████| 10/10 [00:04<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m lerobot.scripts.visualize_dataset \\\n",
    "    --repo-id lerobot/svla_so101_pickplace \\\n",
    "    --episode-index 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35538eb2",
   "metadata": {},
   "source": [
    "## Fine-tuning SmolVAL with sval-so101-pickplace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d542db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"./temp/outputs/svla_so101_pickplace\"\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c424226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2025-09-10 05:15:45 ils/utils.py:48 Cuda backend detected, using cuda.\n",
      "WARNING 2025-09-10 05:15:45 /policies.py:80 Device 'None' is not available. Switching to 'cuda'.\n",
      "INFO 2025-09-10 05:15:46 ts/train.py:111 {'batch_size': 32,\n",
      " 'dataset': {'episodes': None,\n",
      "             'image_transforms': {'enable': False,\n",
      "                                  'max_num_transforms': 3,\n",
      "                                  'random_order': False,\n",
      "                                  'tfs': {'brightness': {'kwargs': {'brightness': [0.8,\n",
      "                                                                                   1.2]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'contrast': {'kwargs': {'contrast': [0.8,\n",
      "                                                                               1.2]},\n",
      "                                                       'type': 'ColorJitter',\n",
      "                                                       'weight': 1.0},\n",
      "                                          'hue': {'kwargs': {'hue': [-0.05,\n",
      "                                                                     0.05]},\n",
      "                                                  'type': 'ColorJitter',\n",
      "                                                  'weight': 1.0},\n",
      "                                          'saturation': {'kwargs': {'saturation': [0.5,\n",
      "                                                                                   1.5]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'sharpness': {'kwargs': {'sharpness': [0.5,\n",
      "                                                                                 1.5]},\n",
      "                                                        'type': 'SharpnessJitter',\n",
      "                                                        'weight': 1.0}}},\n",
      "             'repo_id': 'lerobot/svla_so101_pickplace',\n",
      "             'revision': None,\n",
      "             'root': None,\n",
      "             'use_imagenet_stats': True,\n",
      "             'video_backend': 'torchcodec'},\n",
      " 'env': None,\n",
      " 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},\n",
      " 'eval_freq': 10,\n",
      " 'job_name': 'smolvla',\n",
      " 'log_freq': 200,\n",
      " 'num_workers': 4,\n",
      " 'optimizer': {'betas': [0.9, 0.95],\n",
      "               'eps': 1e-08,\n",
      "               'grad_clip_norm': 10.0,\n",
      "               'lr': 0.0001,\n",
      "               'type': 'adamw',\n",
      "               'weight_decay': 1e-10},\n",
      " 'output_dir': '/home/hyunjae/110_HyunJae_Git/Robot_Drills/VLA/LeRobot/SmolVLA/temp/outputs/svla_so101_pickplace',\n",
      " 'policy': {'adapt_to_pi_aloha': False,\n",
      "            'add_image_special_tokens': False,\n",
      "            'attention_mode': 'cross_attn',\n",
      "            'chunk_size': 50,\n",
      "            'device': 'cuda',\n",
      "            'empty_cameras': 0,\n",
      "            'expert_width_multiplier': 0.75,\n",
      "            'freeze_vision_encoder': True,\n",
      "            'input_features': {'observation.image': {'shape': [3, 256, 256],\n",
      "                                                     'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.image2': {'shape': [3, 256, 256],\n",
      "                                                      'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.image3': {'shape': [3, 256, 256],\n",
      "                                                      'type': <FeatureType.VISUAL: 'VISUAL'>},\n",
      "                               'observation.state': {'shape': [6],\n",
      "                                                     'type': <FeatureType.STATE: 'STATE'>}},\n",
      "            'license': None,\n",
      "            'load_vlm_weights': True,\n",
      "            'max_action_dim': 32,\n",
      "            'max_period': 4.0,\n",
      "            'max_state_dim': 32,\n",
      "            'min_period': 0.004,\n",
      "            'n_action_steps': 50,\n",
      "            'n_obs_steps': 1,\n",
      "            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>},\n",
      "            'num_expert_layers': 0,\n",
      "            'num_steps': 10,\n",
      "            'num_vlm_layers': 16,\n",
      "            'optimizer_betas': [0.9, 0.95],\n",
      "            'optimizer_eps': 1e-08,\n",
      "            'optimizer_grad_clip_norm': 10.0,\n",
      "            'optimizer_lr': 0.0001,\n",
      "            'optimizer_weight_decay': 1e-10,\n",
      "            'output_features': {'action': {'shape': [6],\n",
      "                                           'type': <FeatureType.ACTION: 'ACTION'>}},\n",
      "            'pad_language_to': 'max_length',\n",
      "            'prefix_length': 0,\n",
      "            'private': None,\n",
      "            'push_to_hub': False,\n",
      "            'repo_id': None,\n",
      "            'resize_imgs_with_padding': [512, 512],\n",
      "            'scheduler_decay_lr': 2.5e-06,\n",
      "            'scheduler_decay_steps': 30000,\n",
      "            'scheduler_warmup_steps': 1000,\n",
      "            'self_attn_every_n_layers': 2,\n",
      "            'tags': None,\n",
      "            'tokenizer_max_length': 48,\n",
      "            'train_expert_only': True,\n",
      "            'train_state_proj': True,\n",
      "            'type': 'smolvla',\n",
      "            'use_amp': False,\n",
      "            'use_cache': True,\n",
      "            'use_delta_joint_actions_aloha': False,\n",
      "            'vlm_model_name': 'HuggingFaceTB/SmolVLM2-500M-Video-Instruct'},\n",
      " 'resume': False,\n",
      " 'save_checkpoint': True,\n",
      " 'save_freq': 1000,\n",
      " 'scheduler': {'decay_lr': 2.5e-06,\n",
      "               'num_decay_steps': 30000,\n",
      "               'num_warmup_steps': 1000,\n",
      "               'peak_lr': 0.0001,\n",
      "               'type': 'cosine_decay_with_warmup'},\n",
      " 'seed': 1000,\n",
      " 'steps': 2000,\n",
      " 'use_policy_training_preset': True,\n",
      " 'wandb': {'disable_artifact': False,\n",
      "           'enable': False,\n",
      "           'entity': None,\n",
      "           'mode': None,\n",
      "           'notes': None,\n",
      "           'project': 'lerobot',\n",
      "           'run_id': None}}\n",
      "INFO 2025-09-10 05:15:46 ts/train.py:117 \u001b[1m\u001b[33mLogs will be saved locally.\u001b[0m\n",
      "INFO 2025-09-10 05:15:46 ts/train.py:127 Creating dataset\n",
      "Resolving data files: 100%|█████████████████| 50/50 [00:00<00:00, 178329.25it/s]\n",
      "INFO 2025-09-10 05:15:47 ts/train.py:138 Creating policy\n",
      "Loading  HuggingFaceTB/SmolVLM2-500M-Video-Instruct weights ...\n",
      "INFO 2025-09-10 05:15:53 odeling.py:1004 We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Reducing the number of VLM layers to 16 ...\n",
      "[standardise_state_dict] 'normalize_inputs.buffer_observation_state.mean'  ←  ['normalize_inputs.so100-red_buffer_observation_state.mean', 'normalize_inputs.so100_buffer_observation_state.mean']\n",
      "[standardise_state_dict] 'normalize_inputs.buffer_observation_state.std'  ←  ['normalize_inputs.so100-red_buffer_observation_state.std', 'normalize_inputs.so100_buffer_observation_state.std']\n",
      "[standardise_state_dict] 'normalize_targets.buffer_action.mean'  ←  ['normalize_targets.so100-red_buffer_action.mean', 'normalize_targets.so100_buffer_action.mean']\n",
      "[standardise_state_dict] 'normalize_targets.buffer_action.std'  ←  ['normalize_targets.so100-red_buffer_action.std', 'normalize_targets.so100_buffer_action.std']\n",
      "[standardise_state_dict] 'unnormalize_outputs.buffer_action.mean'  ←  ['unnormalize_outputs.so100-red_buffer_action.mean', 'unnormalize_outputs.so100_buffer_action.mean']\n",
      "[standardise_state_dict] 'unnormalize_outputs.buffer_action.std'  ←  ['unnormalize_outputs.so100-red_buffer_action.std', 'unnormalize_outputs.so100_buffer_action.std']\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:144 Creating optimizer and scheduler\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:156 \u001b[1m\u001b[33mOutput dir:\u001b[0m /home/hyunjae/110_HyunJae_Git/Robot_Drills/VLA/LeRobot/SmolVLA/temp/outputs/svla_so101_pickplace\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:159 cfg.steps=2000 (2K)\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:160 dataset.num_frames=11939 (12K)\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:161 dataset.num_episodes=50\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:162 num_learnable_params=99880992 (100M)\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:163 num_total_params=450046212 (450M)\n",
      "INFO 2025-09-10 05:16:01 ts/train.py:202 Start offline training on a fixed dataset\n",
      "INFO 2025-09-10 05:28:42 ts/train.py:232 step:200 smpl:6K ep:27 epch:0.54 loss:0.099 grdn:0.764 lr:1.0e-05 updt_s:3.798 data_s:0.006\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 05:41:12 ts/train.py:232 step:400 smpl:13K ep:54 epch:1.07 loss:0.049 grdn:0.582 lr:3.0e-05 updt_s:3.740 data_s:0.008\n",
      "INFO 2025-09-10 05:53:23 ts/train.py:232 step:600 smpl:19K ep:80 epch:1.61 loss:0.042 grdn:0.569 lr:5.0e-05 updt_s:3.650 data_s:0.000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 06:05:31 ts/train.py:232 step:800 smpl:26K ep:107 epch:2.14 loss:0.043 grdn:0.591 lr:7.0e-05 updt_s:3.632 data_s:0.008\n",
      "INFO 2025-09-10 06:17:42 ts/train.py:232 step:1K smpl:32K ep:134 epch:2.68 loss:0.042 grdn:0.568 lr:9.0e-05 updt_s:3.649 data_s:0.000\n",
      "INFO 2025-09-10 06:17:42 ts/train.py:241 Checkpoint policy after step 1000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 06:29:52 ts/train.py:232 step:1K smpl:38K ep:161 epch:3.22 loss:0.042 grdn:0.526 lr:1.0e-04 updt_s:3.633 data_s:0.009\n",
      "INFO 2025-09-10 06:42:02 ts/train.py:232 step:1K smpl:45K ep:188 epch:3.75 loss:0.038 grdn:0.471 lr:1.0e-04 updt_s:3.650 data_s:0.000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 06:54:11 ts/train.py:232 step:2K smpl:51K ep:214 epch:4.29 loss:0.038 grdn:0.451 lr:9.9e-05 updt_s:3.633 data_s:0.009\n",
      "INFO 2025-09-10 07:06:22 ts/train.py:232 step:2K smpl:58K ep:241 epch:4.82 loss:0.037 grdn:0.445 lr:9.9e-05 updt_s:3.651 data_s:0.000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 07:18:30 ts/train.py:232 step:2K smpl:64K ep:268 epch:5.36 loss:0.036 grdn:0.419 lr:9.9e-05 updt_s:3.634 data_s:0.007\n",
      "INFO 2025-09-10 07:18:30 ts/train.py:241 Checkpoint policy after step 2000\n",
      "INFO 2025-09-10 07:18:32 ts/train.py:283 End of training\n"
     ]
    }
   ],
   "source": [
    "!python -m lerobot.scripts.train \\\n",
    "    --policy.path=lerobot/smolvla_base \\\n",
    "    --dataset.repo_id=lerobot/svla_so101_pickplace \\\n",
    "    --batch_size=32  \\\n",
    "    --steps=2000 \\\n",
    "    --save_freq=1000 \\\n",
    "    --eval_freq=10 \\\n",
    "    --policy.device=$device \\\n",
    "    --wandb.enable=false \\\n",
    "    --output_dir=.$output_dir \\\n",
    "    --policy.push_to_hub=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fda333",
   "metadata": {},
   "source": [
    "## Preformace Test with the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7815dfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  HuggingFaceTB/SmolVLM2-500M-Video-Instruct weights ...\n",
      "Reducing the number of VLM layers to 16 ...\n",
      "Loading weights from local directory\n",
      "Avg inference time: 0.282433 s\n",
      "Max GPU memory used: 1913.13 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
    "\n",
    "from transformers import AutoProcessor\n",
    " \n",
    "local_path = os.path.join(output_dir, \"checkpoints/last/pretrained_model\")\n",
    "policy = SmolVLAPolicy.from_pretrained(local_path).to(device)\n",
    "policy.eval()\n",
    " \n",
    "# patch: The loaded policy is missing the language_tokenizer attribute.\n",
    "policy.language_tokenizer = AutoProcessor.from_pretrained(policy.config.vlm_model_name).tokenizer\n",
    " \n",
    "# Dummy batch config for a single observation\n",
    "batch_size = 1\n",
    "img_shape = (3, 480, 640)  # (C, H, W)\n",
    "# Infer state_dim from the loaded normalization stats\n",
    "state_dim = policy.normalize_inputs.buffer_observation_state.mean.shape[-1]\n",
    " \n",
    "dummy_batch = {\n",
    "    # a single image observation\n",
    "    \"observation.images.top\": torch.rand(batch_size, *img_shape, device=device),\n",
    "    \"observation.images.side\": torch.rand(batch_size, *img_shape, device=device),\n",
    "    # a single state observation\n",
    "    \"observation.state\": torch.rand(batch_size, state_dim, device=device),\n",
    "    \"task\": [\"stack the blocks\"] * batch_size,\n",
    "}\n",
    " \n",
    "# --- Prepare inputs for the model ---\n",
    "# The policy expects normalized inputs and specific data preparation.\n",
    "normalized_batch = policy.normalize_inputs(dummy_batch)\n",
    "images, img_masks = policy.prepare_images(normalized_batch)\n",
    "state = policy.prepare_state(normalized_batch)\n",
    "lang_tokens, lang_masks = policy.prepare_language(normalized_batch)\n",
    "# ---\n",
    " \n",
    "# Warmup\n",
    "for _ in range(3):\n",
    "    with torch.no_grad():\n",
    "        _ = policy.model.sample_actions(images, img_masks, lang_tokens, lang_masks, state)\n",
    " \n",
    "# Benchmark\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    with torch.no_grad():\n",
    "        _ = policy.model.sample_actions(images, img_masks, lang_tokens, lang_masks, state)\n",
    "end = time.time()\n",
    " \n",
    "print(f\"Avg inference time: {(end - start)/100:.6f} s\")\n",
    "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
