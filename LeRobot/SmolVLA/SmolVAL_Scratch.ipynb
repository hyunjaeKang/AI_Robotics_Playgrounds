{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "babb853d",
   "metadata": {},
   "source": [
    "# Train SmolVLA from scratch\n",
    "\n",
    "---\n",
    "\n",
    "- Conda env : [lerobot](../README.md#setup-a-conda-environment)\n",
    "\n",
    "----\n",
    "\n",
    "- Ref: \n",
    "    - ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ee2dec",
   "metadata": {},
   "source": [
    "### Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efb4fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device : cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Available device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fadbdf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 10 08:31:48 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 67%   59C    P5             42W /  250W |    1579MiB /  11264MiB |     23%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2130      G   /usr/lib/xorg/Xorg                      741MiB |\n",
      "|    0   N/A  N/A            2359      G   /usr/bin/gnome-shell                    134MiB |\n",
      "|    0   N/A  N/A            3725      G   /usr/share/code/code                    454MiB |\n",
      "|    0   N/A  N/A            4105      G   ...ersion=20250909-050100.006000        145MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "if device == \"cuda\":\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c16a5d",
   "metadata": {},
   "source": [
    "## DataSet(svla-so101_pickplace) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d547ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|█████████████████| 50/50 [00:00<00:00, 119905.77it/s]\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[32mINFO \u001b[0m winit::platform_impl::linux::x11::window\u001b[0m\u001b[38;5;8m]\u001b[0m Guessed window scale factor: 1\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::egl\u001b[0m\u001b[38;5;8m]\u001b[0m No config found!\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::egl\u001b[0m\u001b[38;5;8m]\u001b[0m EGL says it can present to the window but not natively\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::adapter\u001b[0m\u001b[38;5;8m]\u001b[0m Max vertex attribute stride unknown. Assuming it is 2048\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::gles::adapter\u001b[0m\u001b[38;5;8m]\u001b[0m Max vertex attribute stride unknown. Assuming it is 2048\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:56Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:57Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "\u001b[0m\u001b[38;5;8m[\u001b[0m2025-09-10T15:31:57Z \u001b[0m\u001b[33mWARN \u001b[0m wgpu_hal::vulkan::conv\u001b[0m\u001b[38;5;8m]\u001b[0m Unrecognized present mode 1000361000\n",
      "100%|███████████████████████████████████████████| 10/10 [00:04<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m lerobot.scripts.visualize_dataset \\\n",
    "    --repo-id lerobot/svla_so101_pickplace \\\n",
    "    --episode-index 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35538eb2",
   "metadata": {},
   "source": [
    "## Fine-tuning SmolVAL with sval-so101-pickplace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d542db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp/outputs/svla_so101_pickplace_scratch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"./temp/outputs/svla_so101_pickplace_scratch\"\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c424226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 2025-09-10 08:32:06 ts/train.py:111 {'batch_size': 32,\n",
      " 'dataset': {'episodes': None,\n",
      "             'image_transforms': {'enable': False,\n",
      "                                  'max_num_transforms': 3,\n",
      "                                  'random_order': False,\n",
      "                                  'tfs': {'brightness': {'kwargs': {'brightness': [0.8,\n",
      "                                                                                   1.2]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'contrast': {'kwargs': {'contrast': [0.8,\n",
      "                                                                               1.2]},\n",
      "                                                       'type': 'ColorJitter',\n",
      "                                                       'weight': 1.0},\n",
      "                                          'hue': {'kwargs': {'hue': [-0.05,\n",
      "                                                                     0.05]},\n",
      "                                                  'type': 'ColorJitter',\n",
      "                                                  'weight': 1.0},\n",
      "                                          'saturation': {'kwargs': {'saturation': [0.5,\n",
      "                                                                                   1.5]},\n",
      "                                                         'type': 'ColorJitter',\n",
      "                                                         'weight': 1.0},\n",
      "                                          'sharpness': {'kwargs': {'sharpness': [0.5,\n",
      "                                                                                 1.5]},\n",
      "                                                        'type': 'SharpnessJitter',\n",
      "                                                        'weight': 1.0}}},\n",
      "             'repo_id': 'lerobot/svla_so101_pickplace',\n",
      "             'revision': None,\n",
      "             'root': None,\n",
      "             'use_imagenet_stats': True,\n",
      "             'video_backend': 'torchcodec'},\n",
      " 'env': None,\n",
      " 'eval': {'batch_size': 50, 'n_episodes': 50, 'use_async_envs': False},\n",
      " 'eval_freq': 10,\n",
      " 'job_name': 'smolvla',\n",
      " 'log_freq': 200,\n",
      " 'num_workers': 4,\n",
      " 'optimizer': {'betas': [0.9, 0.95],\n",
      "               'eps': 1e-08,\n",
      "               'grad_clip_norm': 10,\n",
      "               'lr': 0.0001,\n",
      "               'type': 'adamw',\n",
      "               'weight_decay': 1e-10},\n",
      " 'output_dir': 'temp/outputs/svla_so101_pickplace_scratch',\n",
      " 'policy': {'adapt_to_pi_aloha': False,\n",
      "            'add_image_special_tokens': False,\n",
      "            'attention_mode': 'cross_attn',\n",
      "            'chunk_size': 50,\n",
      "            'device': 'cuda',\n",
      "            'empty_cameras': 0,\n",
      "            'expert_width_multiplier': 0.75,\n",
      "            'freeze_vision_encoder': True,\n",
      "            'input_features': {},\n",
      "            'license': None,\n",
      "            'load_vlm_weights': False,\n",
      "            'max_action_dim': 32,\n",
      "            'max_period': 4.0,\n",
      "            'max_state_dim': 32,\n",
      "            'min_period': 0.004,\n",
      "            'n_action_steps': 50,\n",
      "            'n_obs_steps': 1,\n",
      "            'normalization_mapping': {'ACTION': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'STATE': <NormalizationMode.MEAN_STD: 'MEAN_STD'>,\n",
      "                                      'VISUAL': <NormalizationMode.IDENTITY: 'IDENTITY'>},\n",
      "            'num_expert_layers': -1,\n",
      "            'num_steps': 10,\n",
      "            'num_vlm_layers': 16,\n",
      "            'optimizer_betas': [0.9, 0.95],\n",
      "            'optimizer_eps': 1e-08,\n",
      "            'optimizer_grad_clip_norm': 10,\n",
      "            'optimizer_lr': 0.0001,\n",
      "            'optimizer_weight_decay': 1e-10,\n",
      "            'output_features': {},\n",
      "            'pad_language_to': 'longest',\n",
      "            'prefix_length': -1,\n",
      "            'private': None,\n",
      "            'push_to_hub': False,\n",
      "            'repo_id': None,\n",
      "            'resize_imgs_with_padding': [512, 512],\n",
      "            'scheduler_decay_lr': 2.5e-06,\n",
      "            'scheduler_decay_steps': 30000,\n",
      "            'scheduler_warmup_steps': 1000,\n",
      "            'self_attn_every_n_layers': 2,\n",
      "            'tags': None,\n",
      "            'tokenizer_max_length': 48,\n",
      "            'train_expert_only': True,\n",
      "            'train_state_proj': True,\n",
      "            'type': 'smolvla',\n",
      "            'use_amp': False,\n",
      "            'use_cache': True,\n",
      "            'use_delta_joint_actions_aloha': False,\n",
      "            'vlm_model_name': 'HuggingFaceTB/SmolVLM2-500M-Video-Instruct'},\n",
      " 'resume': False,\n",
      " 'save_checkpoint': True,\n",
      " 'save_freq': 1000,\n",
      " 'scheduler': {'decay_lr': 2.5e-06,\n",
      "               'num_decay_steps': 30000,\n",
      "               'num_warmup_steps': 1000,\n",
      "               'peak_lr': 0.0001,\n",
      "               'type': 'cosine_decay_with_warmup'},\n",
      " 'seed': 1000,\n",
      " 'steps': 2000,\n",
      " 'use_policy_training_preset': True,\n",
      " 'wandb': {'disable_artifact': False,\n",
      "           'enable': False,\n",
      "           'entity': None,\n",
      "           'mode': None,\n",
      "           'notes': None,\n",
      "           'project': 'lerobot',\n",
      "           'run_id': None}}\n",
      "INFO 2025-09-10 08:32:06 ts/train.py:117 \u001b[1m\u001b[33mLogs will be saved locally.\u001b[0m\n",
      "INFO 2025-09-10 08:32:06 ts/train.py:127 Creating dataset\n",
      "Resolving data files: 100%|██████████████████| 50/50 [00:00<00:00, 51225.01it/s]\n",
      "INFO 2025-09-10 08:32:07 ts/train.py:138 Creating policy\n",
      "Reducing the number of VLM layers to 16 ...\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:144 Creating optimizer and scheduler\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:156 \u001b[1m\u001b[33mOutput dir:\u001b[0m temp/outputs/svla_so101_pickplace_scratch\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:159 cfg.steps=2000 (2K)\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:160 dataset.num_frames=11939 (12K)\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:161 dataset.num_episodes=50\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:162 num_learnable_params=99880992 (100M)\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:163 num_total_params=450046212 (450M)\n",
      "INFO 2025-09-10 08:32:28 ts/train.py:202 Start offline training on a fixed dataset\n",
      "INFO 2025-09-10 08:40:38 ts/train.py:232 step:200 smpl:6K ep:27 epch:0.54 loss:1.040 grdn:3.543 lr:1.0e-05 updt_s:2.436 data_s:0.008\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 08:48:46 ts/train.py:232 step:400 smpl:13K ep:54 epch:1.07 loss:0.374 grdn:4.565 lr:3.0e-05 updt_s:2.427 data_s:0.007\n",
      "INFO 2025-09-10 08:56:54 ts/train.py:232 step:600 smpl:19K ep:80 epch:1.61 loss:0.230 grdn:4.934 lr:5.0e-05 updt_s:2.437 data_s:0.001\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 09:05:01 ts/train.py:232 step:800 smpl:26K ep:107 epch:2.14 loss:0.179 grdn:4.370 lr:7.0e-05 updt_s:2.425 data_s:0.009\n",
      "INFO 2025-09-10 09:13:09 ts/train.py:232 step:1K smpl:32K ep:134 epch:2.68 loss:0.148 grdn:3.124 lr:9.0e-05 updt_s:2.435 data_s:0.001\n",
      "INFO 2025-09-10 09:13:09 ts/train.py:241 Checkpoint policy after step 1000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 09:21:19 ts/train.py:232 step:1K smpl:38K ep:161 epch:3.22 loss:0.123 grdn:2.059 lr:1.0e-04 updt_s:2.425 data_s:0.010\n",
      "INFO 2025-09-10 09:29:27 ts/train.py:232 step:1K smpl:45K ep:188 epch:3.75 loss:0.102 grdn:1.486 lr:1.0e-04 updt_s:2.436 data_s:0.001\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 09:37:34 ts/train.py:232 step:2K smpl:51K ep:214 epch:4.29 loss:0.088 grdn:1.156 lr:9.9e-05 updt_s:2.424 data_s:0.008\n",
      "INFO 2025-09-10 09:45:42 ts/train.py:232 step:2K smpl:58K ep:241 epch:4.82 loss:0.081 grdn:0.962 lr:9.9e-05 updt_s:2.434 data_s:0.001\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO 2025-09-10 09:53:49 ts/train.py:232 step:2K smpl:64K ep:268 epch:5.36 loss:0.072 grdn:0.815 lr:9.9e-05 updt_s:2.423 data_s:0.009\n",
      "INFO 2025-09-10 09:53:49 ts/train.py:241 Checkpoint policy after step 2000\n",
      "INFO 2025-09-10 09:53:51 ts/train.py:283 End of training\n"
     ]
    }
   ],
   "source": [
    "!python -m lerobot.scripts.train \\\n",
    "    --policy.type=smolvla \\\n",
    "    --dataset.repo_id=lerobot/svla_so101_pickplace \\\n",
    "    --batch_size=32  \\\n",
    "    --steps=2000 \\\n",
    "    --save_freq=1000 \\\n",
    "    --eval_freq=10 \\\n",
    "    --policy.device=$device \\\n",
    "    --wandb.enable=false \\\n",
    "    --output_dir=$output_dir \\\n",
    "    --policy.push_to_hub=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fda333",
   "metadata": {},
   "source": [
    "## Preformace Test with the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7815dfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyunjae/anaconda3/envs/lerobot/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the number of VLM layers to 16 ...\n",
      "Loading weights from local directory\n",
      "Avg inference time: 0.262490 s\n",
      "Max GPU memory used: 1210.35 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy\n",
    "from lerobot.policies.smolvla.configuration_smolvla import SmolVLAConfig\n",
    "\n",
    "from transformers import AutoProcessor\n",
    " \n",
    "local_path = os.path.join(output_dir, \"checkpoints/last/pretrained_model\")\n",
    "policy = SmolVLAPolicy.from_pretrained(local_path).to(device)\n",
    "policy.eval()\n",
    " \n",
    "# patch: The loaded policy is missing the language_tokenizer attribute.\n",
    "policy.language_tokenizer = AutoProcessor.from_pretrained(policy.config.vlm_model_name).tokenizer\n",
    " \n",
    "# Dummy batch config for a single observation\n",
    "batch_size = 1\n",
    "img_shape = (3, 480, 640)  # (C, H, W)\n",
    "# Infer state_dim from the loaded normalization stats\n",
    "state_dim = policy.normalize_inputs.buffer_observation_state.mean.shape[-1]\n",
    " \n",
    "dummy_batch = {\n",
    "    # a single image observation\n",
    "    \"observation.images.top\": torch.rand(batch_size, *img_shape, device=device),\n",
    "    \"observation.images.side\": torch.rand(batch_size, *img_shape, device=device),\n",
    "    # a single state observation\n",
    "    \"observation.state\": torch.rand(batch_size, state_dim, device=device),\n",
    "    \"task\": [\"stack the blocks\"] * batch_size,\n",
    "}\n",
    " \n",
    "# --- Prepare inputs for the model ---\n",
    "# The policy expects normalized inputs and specific data preparation.\n",
    "normalized_batch = policy.normalize_inputs(dummy_batch)\n",
    "images, img_masks = policy.prepare_images(normalized_batch)\n",
    "state = policy.prepare_state(normalized_batch)\n",
    "lang_tokens, lang_masks = policy.prepare_language(normalized_batch)\n",
    "# ---\n",
    " \n",
    "# Warmup\n",
    "for _ in range(3):\n",
    "    with torch.no_grad():\n",
    "        _ = policy.model.sample_actions(images, img_masks, lang_tokens, lang_masks, state)\n",
    " \n",
    "# Benchmark\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    with torch.no_grad():\n",
    "        _ = policy.model.sample_actions(images, img_masks, lang_tokens, lang_masks, state)\n",
    "end = time.time()\n",
    " \n",
    "print(f\"Avg inference time: {(end - start)/100:.6f} s\")\n",
    "print(f\"Max GPU memory used: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
